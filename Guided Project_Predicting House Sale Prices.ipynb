{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "We will be working with housing data for the city of Ames, Iowa, United States from 2006 to 2010.\n",
    "\n",
    "The data set could be found [here](https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627) and full data description could be found [here](https://s3.amazonaws.com/dq-content/307/data_description.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary modules and read in data set\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with open('AmesHousing.tsv') as f:\n",
    "    df = pd.read_csv(f, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def selected_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "\n",
    "    # split train and test data sets\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # selecting only numerical columns\n",
    "    numeric_train = train.select_dtypes(include=['int', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['int', 'float'])\n",
    "        \n",
    "    # selecting features for model\n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    \n",
    "    # instantiate the model class\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # train model using all numerical columns\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "    \n",
    "    # test model on test set\n",
    "    predictions = lr.predict(test[features])\n",
    "    \n",
    "    # calculate and return RMSE of model\n",
    "    mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = selected_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We will now define a function to clean and prepare the data before we feed it into the model. The general goal of this fuction is to:\n",
    "- remove features that we don't want to use in the model, just based on the number of missing values (25% threshold) or data leakage\n",
    "- transform features into proper format (numerical to categorical, scaling numerical, filling in missing values, ect)\n",
    "- create new features by combining other features\n",
    "\n",
    "We will handle missing values by:\n",
    "- all columns:\n",
    "    - dropping columns with more than 5% missing values **for now**\n",
    "- text columns:\n",
    "    - dropping columns with 1 or more missing values **for now**\n",
    "- numeric columns:\n",
    "    - filling in missing values with column mode **for now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating series that counts sum of missing data in each column\n",
    "num_missing = df.isnull().sum()\n",
    "\n",
    "# creating filter to find columns with >5% missing values\n",
    "dropped_missing_cols = num_missing[(num_missing > len(df)/20)]\n",
    "\n",
    "# dropping the columns from data\n",
    "df = df.drop(dropped_missing_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating series to identify text columns with missing values\n",
    "text_cols = df.select_dtypes(include='object').isnull().sum()\n",
    "\n",
    "# creating filter to identify columns with missing values\n",
    "text_missing_cols = text_cols[(text_cols >= 1)]\n",
    "\n",
    "# dropping columns that have 1 or more missing data\n",
    "df = df.drop(text_missing_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1       1\n",
       "BsmtFin SF 2       1\n",
       "Bsmt Unf SF        1\n",
       "Total Bsmt SF      1\n",
       "Garage Cars        1\n",
       "Garage Area        1\n",
       "Bsmt Full Bath     2\n",
       "Bsmt Half Bath     2\n",
       "Mas Vnr Area      23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifying numeric columns to be filled-in\n",
    "num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "fixable_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'BsmtFin SF 1': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Garage Area': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Mas Vnr Area': 0.0,\n",
       " 'Total Bsmt SF': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating modes for missing values replacements\n",
    "replacement_value_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "replacement_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filling missing values\n",
    "df = df.fillna(replacement_value_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying no more missing values\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create some new features that better capture the information in some of the exisiting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_since_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "years_since_remod[years_since_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating new features\n",
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "# dropping rows with negative value for new features\n",
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "# no longer needing original columns, so remove to avoid collinearity\n",
    "df = df.drop(['Year Built', 'Year Remod/Add'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to drop columns due to reasonings as follow:\n",
    "- columns that aren't useful for machine learning\n",
    "- columns that leak data about the final sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping columns that aren't useful for machine learning\n",
    "df = df.drop(['PID', 'Order'], axis=1)\n",
    "\n",
    "# dropping columns that leak data about final sale\n",
    "df = df.drop(['Yr Sold', 'Mo Sold', 'Sale Condition', 'Sale Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the steps taken for feature engineering, we will update the 'transform_features' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.36731241307"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    dropped_missing_cols = num_missing[(num_missing > len(df)/20)]\n",
    "    df = df.drop(dropped_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include='object').isnull().sum()\n",
    "    text_missing_cols = text_cols[(text_cols >= 1)]\n",
    "    df = df.drop(text_missing_cols.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_value_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_value_dict)\n",
    "    \n",
    "    years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "    years_since_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop(['Year Built', 'Year Remod/Add', 'PID', 'Order', 'Yr Sold', 'Mo Sold', 'Sale Condition', 'Sale Type'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def selected_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "\n",
    "    # split train and test data sets\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # selecting only numerical columns\n",
    "    numeric_train = train.select_dtypes(include=['int', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['int', 'float'])\n",
    "        \n",
    "    # selecting features for model\n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    \n",
    "    # instantiate the model class\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # train model using all numerical columns\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "    \n",
    "    # test model on test set\n",
    "    predictions = lr.predict(test[features])\n",
    "    \n",
    "    # calculate and return RMSE of model\n",
    "    mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t') # note that dataset has to be read in again\n",
    "transformed_df = transform_features(df)\n",
    "filtered_df = selected_features(transformed_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "After cleaning and transforming many features in the data set, we will now try to improve the model by selecting specific numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years Since Remod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>172000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189900</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass  Lot Area  Overall Qual  Overall Cond  Mas Vnr Area  \\\n",
       "0           20     31770             6             5         112.0   \n",
       "1           20     11622             5             6           0.0   \n",
       "2           20     14267             6             6         108.0   \n",
       "3           20     11160             7             5           0.0   \n",
       "4           60     13830             5             5           0.0   \n",
       "\n",
       "   BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  \\\n",
       "0         639.0           0.0        441.0         1080.0        1656   \n",
       "1         468.0         144.0        270.0          882.0         896   \n",
       "2         923.0           0.0        406.0         1329.0        1329   \n",
       "3        1065.0           0.0       1045.0         2110.0        2110   \n",
       "4         791.0           0.0        137.0          928.0         928   \n",
       "\n",
       "         ...          Wood Deck SF  Open Porch SF  Enclosed Porch  3Ssn Porch  \\\n",
       "0        ...                   210             62               0           0   \n",
       "1        ...                   140              0               0           0   \n",
       "2        ...                   393             36               0           0   \n",
       "3        ...                     0              0               0           0   \n",
       "4        ...                   212             34               0           0   \n",
       "\n",
       "   Screen Porch  Pool Area  Misc Val  SalePrice  Years Before Sale  \\\n",
       "0             0          0         0     215000                 50   \n",
       "1           120          0         0     105000                 49   \n",
       "2             0          0     12500     172000                 52   \n",
       "3             0          0         0     244000                 42   \n",
       "4             0          0         0     189900                 13   \n",
       "\n",
       "   Years Since Remod  \n",
       "0                 50  \n",
       "1                 49  \n",
       "2                 52  \n",
       "3                 42  \n",
       "4                 12  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = transformed_df.select_dtypes(include=['int', 'float'])\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2         0.006127\n",
       "Misc Val             0.019273\n",
       "3Ssn Porch           0.032268\n",
       "Bsmt Half Bath       0.035875\n",
       "Low Qual Fin SF      0.037629\n",
       "Pool Area            0.068438\n",
       "MS SubClass          0.085128\n",
       "Overall Cond         0.101540\n",
       "Screen Porch         0.112280\n",
       "Kitchen AbvGr        0.119760\n",
       "Enclosed Porch       0.128685\n",
       "Bedroom AbvGr        0.143916\n",
       "Bsmt Unf SF          0.182751\n",
       "Lot Area             0.267520\n",
       "2nd Flr SF           0.269601\n",
       "Bsmt Full Bath       0.276258\n",
       "Half Bath            0.284871\n",
       "Open Porch SF        0.316262\n",
       "Wood Deck SF         0.328183\n",
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate correlation heatmap matrix of numerical features in the training data set\n",
    "abs_corr_coeff = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "abs_corr_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set arbitary threshold of 0.4 as our minimum correlation threshold, and select only features that have correlation above 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_coeff[abs_corr_coeff > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_df = transformed_df.drop(abs_corr_coeff[abs_corr_coeff < 0.4].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now turn our attention to the categorial data we have yet to pick out and process from the data set. All columns that can be categorized as nominal variables are possible candidates, but there are some other things to think about:\n",
    "- if a categorial column has too many unique values, conversion via dummy method will result in addition of large quantity of dummies to model, which might not be ideal.\n",
    "- if a categorical column have majority of its values in one category (eg. >95%), it will cause issues similar to numerical data with low variance, in that there will be little to no variability in the data for the model to capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the documentation, pick out the nominal varibles\n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Street           2\n",
       "Central Air      2\n",
       "Land Contour     4\n",
       "Lot Config       5\n",
       "Bldg Type        5\n",
       "Roof Style       6\n",
       "Foundation       6\n",
       "Heating          6\n",
       "MS Zoning        7\n",
       "Condition 2      8\n",
       "House Style      8\n",
       "Roof Matl        8\n",
       "Condition 1      9\n",
       "Exterior 1st    16\n",
       "Exterior 2nd    17\n",
       "Neighborhood    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select categorical candidates from the transformed data set after correlation test\n",
    "transform_cat_cols = []\n",
    "for cols in nominal_features:\n",
    "    if cols in transformed_df.columns:\n",
    "        transform_cat_cols.append(cols)\n",
    "        \n",
    "# check number of categories each candidate include\n",
    "uniqueness_count = transformed_df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "uniqueness_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select arbitary cutoff at 10, drop features that have too many features\n",
    "drop_hetero_cols = uniqueness_count[uniqueness_count > 10].index\n",
    "transformed_df = transformed_df.drop(drop_hetero_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS Zoning       object\n",
       "Street          object\n",
       "Land Contour    object\n",
       "Lot Config      object\n",
       "Condition 1     object\n",
       "Condition 2     object\n",
       "Bldg Type       object\n",
       "House Style     object\n",
       "Roof Style      object\n",
       "Roof Matl       object\n",
       "Foundation      object\n",
       "Heating         object\n",
       "Central Air     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_cat = []\n",
    "for cols in nominal_features:\n",
    "    if cols in transformed_df.columns:\n",
    "        remaining_cat.append(cols)\n",
    "transformed_df[remaining_cat].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS Zoning',\n",
       " 'Street',\n",
       " 'Land Contour',\n",
       " 'Lot Config',\n",
       " 'Condition 1',\n",
       " 'Condition 2',\n",
       " 'Bldg Type',\n",
       " 'House Style',\n",
       " 'Roof Style',\n",
       " 'Roof Matl',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'Central Air']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_text = []\n",
    "for cols in remaining_cat:\n",
    "    if cols in transformed_df.select_dtypes(include='object').columns:\n",
    "        remaining_text.append(cols)\n",
    "remaining_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert remaining text columns into categorical dtypes and add to transformed_df\n",
    "for col in remaining_text:\n",
    "    transformed_df[col] = transformed_df[col].astype('category')\n",
    "    \n",
    "# get dummies for categorical columns in the main dataframe\n",
    "transformed_df = pd.concat([\n",
    "    transformed_df,\n",
    "    pd.get_dummies(transformed_df.select_dtypes(include=['category']))\n",
    "], axis=1).drop(remaining_text, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update selected_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36623.53562910476"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    dropped_missing_cols = num_missing[(num_missing > len(df)/20)]\n",
    "    df = df.drop(dropped_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include='object').isnull().sum()\n",
    "    text_missing_cols = text_cols[(text_cols >= 1)]\n",
    "    df = df.drop(text_missing_cols.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_value_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_value_dict)\n",
    "    \n",
    "    years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "    years_since_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop(['Year Built', 'Year Remod/Add', 'PID', 'Order', 'Yr Sold', 'Mo Sold', 'Sale Condition', 'Sale Type'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def selected_features(df, corr_coeff_threshold=0.4, uniqueness_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeff = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeff[abs_corr_coeff < corr_coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    transform_cat_cols = []\n",
    "    for cols in nominal_features:\n",
    "        if cols in df.columns:\n",
    "            transform_cat_cols.append(cols)\n",
    "        \n",
    "    uniqueness_count = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_hetero_cols = uniqueness_count[uniqueness_count > uniqueness_threshold].index\n",
    "    df = df.drop(drop_hetero_cols, axis=1)\n",
    "    \n",
    "    remaining_text = df.select_dtypes(include='object')\n",
    "    for col in remaining_text:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(remaining_text, axis=1)\n",
    "    return df\n",
    "\n",
    "def train_and_test(df):\n",
    "\n",
    "    # split train and test data sets\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # selecting only numerical columns\n",
    "    numeric_train = train.select_dtypes(include=['int', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['int', 'float'])\n",
    "        \n",
    "    # selecting features for model\n",
    "    features = numeric_train.columns.drop('SalePrice')\n",
    "    \n",
    "    # instantiate the model class\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # train model using all numerical columns\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "    \n",
    "    # test model on test set\n",
    "    predictions = lr.predict(test[features])\n",
    "    \n",
    "    # calculate and return RMSE of model\n",
    "    mse = mean_squared_error(test['SalePrice'], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t') # note that dataset has to be read in again\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = selected_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that rmse with modified feature selection fuction is 36623.54, which is an improvement from the previous model (feature engineering only) with rmse 55275.37."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "Now we will explore the difference to resulting rmse by implementing k-fold technique during model testing. We will be investigating changes to rmse with different number of folds (k-value).\n",
    "\n",
    "We will be using the dataframe that has been processed via feature engineering and selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927, 130)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uint8      116\n",
       "int64        9\n",
       "float64      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36623.53562910476"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training and testing the data when k=0 (ie. holdout validation)\n",
    "\n",
    "numeric_filtered = filtered_df.select_dtypes(include=[\"float\", \"int\"])\n",
    "\n",
    "train = numeric_filtered[:1460]\n",
    "test = numeric_filtered[1460:]\n",
    "\n",
    "features = train.columns.drop(\"SalePrice\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(train[features], train[\"SalePrice\"])\n",
    "predictions = lr.predict(test[features])\n",
    "mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34208.65606772392"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set k=1 and perform simple cross validation\n",
    "# Randomize *all* rows (frac=1) from `df` and return\n",
    "shuffled_df = filtered_df.sample(frac=1, )\n",
    "\n",
    "numeric_filtered = shuffled_df.select_dtypes(include=[\"float\", \"int\"])\n",
    "\n",
    "fold_one = numeric_filtered[:1460]\n",
    "fold_two = numeric_filtered[1460:]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(fold_one[features], fold_one[\"SalePrice\"])\n",
    "predictions_one = lr.predict(fold_two[features])\n",
    "mse_one = mean_squared_error(fold_two[\"SalePrice\"], predictions_one)\n",
    "rmse_one = np.sqrt(mse_one)\n",
    "\n",
    "lr.fit(fold_two[features], fold_two[\"SalePrice\"])\n",
    "predictions_two = lr.predict(fold_one[features])\n",
    "mse_two = mean_squared_error(fold_one[\"SalePrice\"], predictions_two)\n",
    "rmse_two = np.sqrt(mse_two)\n",
    "\n",
    "average_rmse = np.mean([rmse_one, rmse_two])\n",
    "average_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32850.43443848478"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k greather than 1, we will implement KFold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "numeric_filtered = filtered_df.select_dtypes(include=[\"float\",\"int\"])\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "# choose arbitary number of folds k=4\n",
    "rmse_values = []\n",
    "for train_index, test_index in kf.split(numeric_filtered):\n",
    "    train = numeric_filtered.iloc[train_index]\n",
    "    test = numeric_filtered.iloc[test_index]\n",
    "    lr.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse_values.append(rmse)\n",
    "avg_rmse = np.mean(rmse_values)\n",
    "avg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33396.97370534905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    dropped_missing_cols = num_missing[(num_missing > len(df)/20)]\n",
    "    df = df.drop(dropped_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include='object').isnull().sum()\n",
    "    text_missing_cols = text_cols[(text_cols >= 1)]\n",
    "    df = df.drop(text_missing_cols.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_value_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_value_dict)\n",
    "    \n",
    "    years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "    years_since_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop(['Year Built', 'Year Remod/Add', 'PID', 'Order', 'Yr Sold', 'Mo Sold', 'Sale Condition', 'Sale Type'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def selected_features(df, corr_coeff_threshold=0.4, uniqueness_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeff = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeff[abs_corr_coeff < corr_coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    transform_cat_cols = []\n",
    "    for cols in nominal_features:\n",
    "        if cols in df.columns:\n",
    "            transform_cat_cols.append(cols)\n",
    "        \n",
    "    uniqueness_count = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_hetero_cols = uniqueness_count[uniqueness_count > uniqueness_threshold].index\n",
    "    df = df.drop(drop_hetero_cols, axis=1)\n",
    "    \n",
    "    remaining_text = df.select_dtypes(include='object')\n",
    "    for col in remaining_text:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(remaining_text, axis=1)\n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=4):\n",
    "    # selecting only numerical columns\n",
    "    numeric_df = df.select_dtypes(include=[\"int\", \"float\"])\n",
    "    # instantiate the model class\n",
    "    lr = LinearRegression()\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    if k==0:\n",
    "        train = numeric_df[:1460]\n",
    "        test = numeric_df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        return rmse\n",
    "\n",
    "    if k==1:\n",
    "        shuffled_df = numeric_df.sample(frac=1, )\n",
    "\n",
    "        fold_one = shuffled_df[:1460]\n",
    "        fold_two = shuffled_df[1460:]\n",
    "        \n",
    "        lr.fit(fold_one[features], fold_one[\"SalePrice\"])\n",
    "        predictions_one = lr.predict(fold_two[features])\n",
    "        mse_one = mean_squared_error(fold_two[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "\n",
    "        lr.fit(fold_two[features], fold_two[\"SalePrice\"])\n",
    "        predictions_two = lr.predict(fold_one[features])\n",
    "        mse_two = mean_squared_error(fold_one[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        average_rmse = np.mean([rmse_one, rmse_two])\n",
    "        return average_rmse\n",
    "    \n",
    "    else:\n",
    "        from sklearn.model_selection import KFold\n",
    "\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index in kf.split(numeric_df):\n",
    "            train = numeric_filtered.iloc[train_index]\n",
    "            test = numeric_filtered.iloc[test_index]\n",
    "            \n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n",
    "\n",
    "df = pd.read_csv('AmesHousing.tsv', delimiter='\\t') # note that dataset has to be read in again\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = selected_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We constructed multiple linear regression models to estimate house sale prices.\n",
    "\n",
    "As we fine tune the specifications of the model, we find that we were able to keep reducing root mean square error, which we took as a measure to the accuracy of the model.\n",
    "\n",
    "As linear models are only able to take in numerical variables, we focused on these variables to perform transformations that aims to reduce bias and error introduced to the model. For text variables, we only looked into categorical variables, and opted only to keep the ones that proved to provide enough homogeneity to be useful for analysis.\n",
    "\n",
    "Then we looked at improving the model via hyperparameter optimisation. In this instance, we choose to conduct cross validation with the K-Fold technique."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
